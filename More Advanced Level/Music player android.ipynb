{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad6e376",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'label_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f2b1d0b34740>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlabel_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0murlopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'label_image'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import label_image\n",
    "import os,random,subprocess\n",
    "import  numpy as np\n",
    "from urllib.request import  urlopen\n",
    "import time\n",
    "from playsound import playsound\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6348d9fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ec168f180aad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'haarcascade_frontalface_alt.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmobile_video\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"http://192.168.0.109:8080/shot.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# Using default WebCam connected to the PC.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# We load the xml file\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "mobile_video=\"http://192.168.0.109:8080/shot.jpg\"\n",
    "now = time.time()\n",
    "future = now + 15\n",
    "  # Using default WebCam connected to the PC.\n",
    "\n",
    "while True:\n",
    "\n",
    "    img_resp = urlopen(mobile_video)\n",
    "    img_arr = np.array(bytearray(img_resp.read()), dtype=np.uint8)\n",
    "\n",
    "    cap = cv2.imdecode(img_arr, -1)\n",
    "    im=cv2.flip(cap,1,0)\n",
    "    mini = cv2.resize(im, (int(im.shape[1] / size), int(im.shape[0] / size)))\n",
    "\n",
    "    # detect MultiScale / faces\n",
    "    faces = classifier.detectMultiScale(mini)\n",
    "    global text\n",
    "\n",
    "    # Draw rectangles around each face\n",
    "    for f in faces:\n",
    "        (x, y, w, h) = [v * size for v in f]  # Scale the shapesize backup\n",
    "        sub_face = im[y:y + h, x:x + w]\n",
    "        FaceFileName = \"test.jpg\"  # Saving the current image from the webcam for testing.\n",
    "        cv2.imwrite(FaceFileName, sub_face)\n",
    "        text = label_image.main(FaceFileName)  # Getting the Result from the label_image file, i.e., Classification Result.\n",
    "        text = text.title()  # Title Case looks Stunning.\n",
    "        font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "\n",
    "        if text == 'Angry':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0, 25, 255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0, 25,255), 2)\n",
    "\n",
    "        if text == 'Smile':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0,260,0), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0,260,0), 2)\n",
    "\n",
    "        if text == 'Fear':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0, 255, 255), 2)\n",
    "\n",
    "        if text == 'Sad':\n",
    "            cv2.rectangle(im, (x, y), (x + w, y + h), (0,191,255), 7)\n",
    "            cv2.putText(im, text, (x + h, y), font, 1, (0,191,255), 2)\n",
    "\n",
    "    # Show the image/\n",
    "    cv2.imshow('Music player with Emotion recognition', im)\n",
    "    key = cv2.waitKey(30)& 0xff\n",
    "    if time.time() > future:##after 20second music will play\n",
    "        try:\n",
    "            cv2.destroyAllWindows()\n",
    "            mp = 'C:/Program Files (x86)/Windows Media Player/wmplayer.exe'\n",
    "            if text == 'Angry':\n",
    "                randomfile = random.choice(os.listdir(\"C:/Users/kusha/PycharmProjects/Music_player_with_Emotions_recognition/songs/Angry/\"))\n",
    "                print('You are angry !!!! please calm down:) ,I will play song for you :' + randomfile)\n",
    "                file = ('C:/Users/kusha/PycharmProjects/Music_player_with_Emotions_recognition/songs/Angry/' + randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "\n",
    "            if text == 'Smile':\n",
    "                randomfile = random.choice(os.listdir(\"C:/Users/kusha/PycharmProjects/Music_player_with_Emotions_recognition/songs/Smile/\"))\n",
    "                print('You are smiling :) ,I playing special song for you: ' + randomfile)\n",
    "                file = ('C:/Users/kusha/PycharmProjects/Music_player_with_Emotions_recognition/songs/Smile/' + randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "\n",
    "            if text == 'Fear':\n",
    "                randomfile = random.choice(os.listdir(\"C:/Users/kusha/PycharmProjects/Music_player_with_Emotions_recognition/songs/Fear/\"))\n",
    "                print('You have fear of something ,I playing song for you: ' + randomfile)\n",
    "                file = ('C:/Users/kusha/PycharmProjects/Music_player_with_Emotions_recognition/songs/Fear/' + randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "\n",
    "            if text == 'Sad':\n",
    "                randomfile = random.choice(os.listdir(\"C:/Users/kusha/PycharmProjects/Music_player_with_Emotions_recognition/songs/Sad/\"))\n",
    "                print('You are sad,dont worry:) ,I playing song for you: ' + randomfile)\n",
    "                file = ('C:/Users/kusha/PycharmProjects/Music_player_with_Emotions_recognition/songs/Sad/' + randomfile)\n",
    "                subprocess.call([mp, file])\n",
    "            break\n",
    "\n",
    "        except :\n",
    "            print('Please stay focus in Camera frame atleast 15 seconds & run again this program:)')\n",
    "            break\n",
    "\n",
    "    if key == 27:  # The Esc key\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37083496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
